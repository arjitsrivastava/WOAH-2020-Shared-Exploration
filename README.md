# WOAH-2020-Shared-Exploration

Theme of Shared Exploration Task: **Bias and Unfairness in the Detection of Online Abuse**

Shared Exploration papers due: **September 7, 2020 (23h59, GMT-12,"anywhere on Earth")**

Camera ready papers due: **October 14, 2020**

**Details of the evaluation:**

> Advancement: Generation of new academic knowledge which addresses existing problems in the field, or identifies new problems. You should clearly outline the problem you are addressing and how your analyses respond to it.

> Innovation: Application of new methods, techniques and approaches. This could include combining social scientific methods and theories with advanced engineering solutions.

> Rigour: Specification of a clear research question and a well-executed, well-explained and fully considered research design. This could include integrating the Wikipedia Detox dataset with other sources of data and/or other training datasets.

**Methodology in mind:**

**We encourage you to explore interesting, unusual and novel analyses and to integrate social scientific insights with advanced engineering where possible. Approaches which consider the wider implications of the results and address social questions are encouraged.** 

**Possibilites of tasks:**

- How to best aggregate and combine annotations (and what the impact is on the performance, explainability, generalisability, and applicability of models)
- Identifying and evaluating biases
- Measures for mitigating biases
- Enhancing, measuring and balancing model efficiency. Issues you could consider are model size, simplicity, run time, computational requirements and environmental impact.
- Biases which emerge in cross-domain application of models and model generalisability (you may want to explore a secondary dataset).
- Error evaluation, reduction and investigation, such as systematically investigating what types of content generate the most errors.

